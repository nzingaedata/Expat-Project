{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd7d525",
   "metadata": {},
   "source": [
    "# Job Listing Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c0c39",
   "metadata": {},
   "source": [
    "Dataset created from scraping job engine sites including Glassdoor, Indeed, LinkedIn, and Angel using Python's Selenium library and scrapes for the following fields: \n",
    "\n",
    "1. **Company Name**: Name of the company\n",
    "2. **Job Title**: The title of job, eg. Data scientist, junior data scientist, senior data scientist etc.\n",
    "3. **Job Description**: Tells us what is expected out of the job title.\n",
    "4. **Job Requirement**: Required skills\n",
    "5. **Salary Estimate**: Range of salary and the source.\n",
    "6. **Benefits**: Benefits offered by the company including medical insurance, equity, etc.\n",
    "7. **Location**: Location of the job\n",
    "8. **Size**: Range of number of employee working in the company\n",
    "9. **Rating**: It gives the rating of the company\n",
    "10. **Review**: Employee Reviews\n",
    "11. **Industry**: Industry of the company\n",
    "12. **Sector**: Sector in which company works\n",
    "13. **Revenue**: Total revenue of the company per year\n",
    "14. **Num Listings**: Total number of job listings for a country "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbd660",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chromedriver - https://sites.google.com/chromium.org/driver/\n",
    "#pip install -U selenium\n",
    "#conda install -c conda-forge python-dotenv\n",
    "#conda install -c conda-forge webdriver-manager\n",
    "#conda install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d1ec1",
   "metadata": {},
   "source": [
    "### Add Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0078cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm # works for both terminal and notebook\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium.webdriver.support.wait import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0b7a0",
   "metadata": {},
   "source": [
    "### Initialize Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cbbd383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_setup(env_var, url):\n",
    "    \n",
    "    load_dotenv(find_dotenv()) # search for .env file\n",
    "    CHROME_DRIVER = os.environ[env_var]\n",
    "    os.chmod(CHROME_DRIVER, 755) # for unix/lenux computers only, gives file read/execute rights \n",
    "    options = Options()\n",
    "    service = Service(CHROME_DRIVER)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "    driver.get(url)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f72c40",
   "metadata": {},
   "source": [
    "### Glassdoor Job Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d60459d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(url, env_var, num_jobs=30, verbose=False, slp_time=5):\n",
    "\n",
    "    driver = driver_setup(env_var, url)\n",
    "    \n",
    "    jobs = []\n",
    "    jobs_count = len(jobs)\n",
    "    pbar = tqdm(total=num_jobs) # Init progress bar\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    result = re.search(r\"SRCH_IL\", url) # Check URL for countries that were typed into search bar\n",
    "    \n",
    "    if result:\n",
    "        country = re.search(r'Job\\/(.*?)-data-scientist', url).group(1)\n",
    "    else:\n",
    "        try:\n",
    "            country = driver.find_element(By.XPATH, '//div[@class=\"css-m3gjah egu3u860\"]/div[@class=\"selectedLabel\"]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            country = np.nan\n",
    "    \n",
    "    print(\"Country:\", country)\n",
    "    \n",
    "    try:\n",
    "        total_listings = driver.find_element(By.XPATH, \"//p[@data-test='jobsCount']\").text.split()\n",
    "            \n",
    "        if len(total_listings) == 0:\n",
    "            total_listings = int(driver.find_element(By.XPATH, \"//h1[@data-test='jobCount-H1title']\").text.split()[0])\n",
    "        else:\n",
    "            total_listings = int(total_listings[0])\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "            total_listings = np.nan \n",
    "            \n",
    "    \n",
    "    if num_jobs > total_listings:\n",
    "        \n",
    "        print(\"The number of jobs to be scrapped: {} exceeds the number of listings: {}\".format(num_jobs, total_listings))\n",
    "        num_jobs = total_listings\n",
    "        print(\"The number of jobs has been updated to reflect the number of listings\")\n",
    "        print(\"\")\n",
    "    \n",
    "    \n",
    "    print(\"Total number of job listings: {}, number of jobs to be scraped: {}\".format(total_listings, num_jobs))\n",
    "    print(\"\")\n",
    "\n",
    "    while jobs_count < num_jobs:\n",
    "        \n",
    "        time.sleep(slp_time)\n",
    "        time.sleep(.1)\n",
    "        \n",
    "        job_listings = driver.find_elements(By.CLASS_NAME, \"react-job-listing\")\n",
    "        \n",
    "        for listing in job_listings:\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "            if jobs_count >= num_jobs:\n",
    "                print(\"Scraping completed, scraped {} of {} jobs\".format(jobs_count, num_jobs))\n",
    "                break\n",
    "            \n",
    "            listing.click()\n",
    "            time.sleep(2)   \n",
    "\n",
    "            \n",
    "            try:\n",
    "                driver.find_element(By.XPATH, \"//div[@class='qual_x_close']\").click()  #In case survey pops up. \n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            try: \n",
    "                driver.find_element(By.XPATH, \"//span[@alt='Close']\").click()  #clicking to the X.   \n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            \n",
    "            collected_successfully = False\n",
    "            \n",
    "            while not collected_successfully:\n",
    "                try:\n",
    "                    job_title = driver.find_element(By.XPATH,'//div[@class=\"css-1j389vi e1tk4kwz2\"]').text.strip()\n",
    "                    location = driver.find_element(By.XPATH,'//div[@class=\"css-56kyx5 e1tk4kwz1\"]').text.strip()\n",
    "                    job_description = driver.find_element(By.XPATH,'//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "                    collected_successfully = True        \n",
    "                except:\n",
    "                    time.sleep(slp_time)\n",
    "\n",
    "            try: # sometimes there are listings that are posted without a company name\n",
    "                company_name = driver.find_element(By.XPATH,'//div[@class=\"css-xuk5ye e1tk4kwz5\"]').text.strip() #returns any element which is direct parent.\n",
    "            except:\n",
    "                company_name = np.nan\n",
    "            \n",
    "            try:\n",
    "                salary_range = driver.find_element(By.XPATH, '//span[@class=\"css-1hbqxax e1wijj240\"]').text.strip()\n",
    "            except NoSuchElementException:\n",
    "                salary_range = np.nan\n",
    "\n",
    "            try:\n",
    "                salary_avg = driver.find_element(By.XPATH, '//div[@class=\"css-y2jiyn e2u4hf18\"]').text.strip()\n",
    "                salary_avg = salary_avg.split()[0]\n",
    "            except NoSuchElementException:\n",
    "                salary_avg = np.nan\n",
    "\n",
    "            \n",
    "            # Search for Company Container\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.ID, 'CompanyContainer')\n",
    "                \n",
    "                try:\n",
    "                    size = driver.find_element(By.XPATH, \n",
    "                                               '(//div[@class=\"d-flex justify-content-start css-daag8o e1pvx6aw2\"])[1]//span[2]').text.strip()\n",
    "    \n",
    "                except NoSuchElementException:\n",
    "                    size = np.nan\n",
    "\n",
    "                try:\n",
    "                    industry = driver.find_element(By.XPATH, \n",
    "                                               '(//div[@class=\"d-flex justify-content-start css-daag8o e1pvx6aw2\"])[4]//span[2]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    industry = np.nan\n",
    "\n",
    "                try:\n",
    "                    sector = driver.find_element(By.XPATH, \n",
    "                                               '(//div[@class=\"d-flex justify-content-start css-daag8o e1pvx6aw2\"])[5]//span[2]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    sector = np.nan\n",
    "\n",
    "                try:\n",
    "                    revenue = driver.find_element(By.XPATH, \n",
    "                                               '(//div[@class=\"d-flex justify-content-start css-daag8o e1pvx6aw2\"])[6]//span[2]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    revenue = np.nan\n",
    "\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                size = np.nan\n",
    "                industry = np.nan\n",
    "                sector = np.nan\n",
    "                revenue = np.nan\n",
    "\n",
    "            \n",
    "            # Search for Reviews Container\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, '//div[@data-test=\"company-ratings\"]')\n",
    "\n",
    "                try:\n",
    "                    rating = float(driver.find_element(By.XPATH, '//div[@class=\"mr-sm css-ey2fjr e1pr2f4f3\"]').text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    rating = np.nan\n",
    "\n",
    "                try:\n",
    "                    recommend = driver.find_element(By.XPATH, '(//div[@class=\"d-flex top css-rkhv2t e1o78bat1\"])[1]//div[1]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    recommend = np.nan\n",
    "\n",
    "                try:\n",
    "                    ceo = driver.find_element(By.XPATH, '//div[@class=\"css-vkhqai ceoApprove\"]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    ceo = np.nan\n",
    "\n",
    "                try:\n",
    "                    opportunities = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[3]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    opportunities = np.nan\n",
    "                try:\n",
    "                    comp_benefits = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[6]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    comp_benefits = np.nan\n",
    "\n",
    "                try:\n",
    "                    culture = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[9]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    culture = np.nan\n",
    "\n",
    "                try:\n",
    "                    management = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[12]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    management = np.nan\n",
    "\n",
    "                try:\n",
    "                    workLife = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[15]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    workLife = np.nan\n",
    "\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                rating = np.nan\n",
    "                recommend = np.nan\n",
    "                ceo = np.nan\n",
    "                opportunities = np.nan\n",
    "                comp_benefits = np.nan\n",
    "                culture = np.nan\n",
    "                management = np.nan\n",
    "                workLife = np.nan\n",
    "\n",
    "\n",
    "            # Get Employee Reviews\n",
    "            try: \n",
    "                driver.find_element(By.ID, 'ReviewsContainer')\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    pro_reviews = driver.find_element(By.XPATH, \n",
    "                                                      '(//div[@class=\"css-1sfecah e1vn3ovn1\"])[1]//div') # check for pros\n",
    "\n",
    "                    pro_reviews = pro_reviews.find_elements(By.XPATH, \"following-sibling::p\")\n",
    "                    pros = [review.text for review in pro_reviews]  \n",
    "\n",
    "                except NoSuchElementException: \n",
    "                    pros = np.nan\n",
    "\n",
    "                try:\n",
    "                    con_reviews = driver.find_element(By.XPATH, \n",
    "                                                      '(//div[@class=\"css-1sfecah e1vn3ovn1\"])[2]//div')\n",
    "\n",
    "                    con_reviews = con_reviews.find_elements(By.XPATH, \"following-sibling::p\")\n",
    "                    cons = [review.text for review in con_reviews]    \n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    cons = np.nan\n",
    "\n",
    "            except NoSuchElementException: \n",
    "                pros = np.nan\n",
    "                cons = np.nan\n",
    "\n",
    "            # Get Benefits Rating and Reviews\n",
    "            try: \n",
    "                driver.find_element(By.CLASS_NAME, 'p-std')\n",
    "\n",
    "                try: \n",
    "                    benefits_rating = float(driver.find_element(By.XPATH, '//div[@class=\"ratingNum mr-sm\"]').text.strip())\n",
    "\n",
    "                except NoSuchElementException: \n",
    "                    benefits_rating = np.nan\n",
    "\n",
    "            except NoSuchElementException: \n",
    "                benefits_rating = np.nan\n",
    "                \n",
    "\n",
    "            jobs.append({\"Company Name\": company_name,\n",
    "                        \"Job Title\": job_title, \n",
    "                        \"Location\": location,\n",
    "                        \"Country\": country,\n",
    "                        \"Job Description\": job_description, \n",
    "                        \"Salary Estimate\": salary_range,\n",
    "                        \"Avg Salary\": salary_avg,\n",
    "                        \"Size\": size,\n",
    "                        \"Industry\": industry,\n",
    "                        \"Sector\": sector,\n",
    "                        \"Revenue\": revenue,\n",
    "                        \"Rating\": rating,\n",
    "                        \"Recommend\": recommend,\n",
    "                        \"CEO\": ceo,\n",
    "                        \"Benefits\": benefits_rating,\n",
    "                        \"Opportunities\": opportunities,\n",
    "                        \"Comp Benefits\": comp_benefits,\n",
    "                        \"Culture\": culture,\n",
    "                        \"Management\": management,\n",
    "                        \"WorkLife Balance\": workLife,\n",
    "                        \"Pros\": pros,\n",
    "                        \"Cons\": cons,\n",
    "                        \"Num Listings\": total_listings})\n",
    "            \n",
    "        \n",
    "            jobs_count = len(jobs)\n",
    "            \n",
    "            if not verbose:\n",
    "                print(\"Scraped {} out of {} job listings\".format(jobs_count, num_jobs), end='\\r')\n",
    "            \n",
    "            # print for debugging purposes\n",
    "            if verbose:\n",
    "                print(\"Company Name: {}\".format(company_name))\n",
    "                print(\"Job Title: {}\".format(job_title))\n",
    "                print(\"Location: {}\".format(location))\n",
    "                print(\"Country: {}\".format(country))\n",
    "                print(\"Job Description: {}\".format(job_description[:500]))\n",
    "                print(\"Salary Estimate: {}\".format(salary_range))\n",
    "                print(\"Avg Salary: {}\".format(salary_avg))\n",
    "                print(\"Size: {}\".format(size))\n",
    "                print(\"Industry: {}\".format(industry))\n",
    "                print(\"Sector: {}\".format(sector))\n",
    "                print(\"Revenue: {}\".format(revenue))\n",
    "                print(\"Rating: {}\".format(rating))\n",
    "                print(\"Recommend To Friend: {}\".format(recommend))\n",
    "                print(\"Approve of CEO: {}\".format(ceo))\n",
    "                print(\"Benefits Rating: {}\".format(benefits_rating))\n",
    "                print(\"Career Opportunities: {}\".format(opportunities))\n",
    "                print(\"Comp & Benefits: {}\".format(comp_benefits))\n",
    "                print(\"Culture & Values: {}\".format(culture))\n",
    "                print(\"Senior Managment: {}\".format(management))\n",
    "                print(\"Work Life Balance: {}\".format(workLife))\n",
    "                print(\"Pros: \", pros)\n",
    "                print(\"Cons: \", cons)\n",
    "                print(\"\")\n",
    "                print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "                print(\"\")\n",
    "\n",
    "        # clicking on the \"next page button\"\n",
    "\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, '//button[@data-test=\"pagination-next\"]').click()\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping completed, scraped {}, out of {} job listings.\".format(jobs_count, num_jobs))\n",
    "            break\n",
    " \n",
    "    \n",
    "    pbar.close()\n",
    "    driver.close()\n",
    "    return pd.DataFrame(jobs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c58eaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime&remoteWorkType=1&sortBy=date_desc',\n",
    "        'https://www.glassdoor.com.ar/Empleo/data-scientist-empleos-SRCH_KO0,14.htm?jobType=fulltime', \n",
    "        'https://www.glassdoor.com.au/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://nl.glassdoor.be/Vacature/data-scientist-vacatures-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://fr.glassdoor.be/Emploi/data-scientist-emplois-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com.br/Vaga/data-scientist-vagas-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.ca/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://fr.glassdoor.ca/Emploi/data-scientist-emplois-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.de/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.es/Empleo/data-scientist-empleos-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.fr/Emploi/data-scientist-emplois-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com.hk/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.co.in/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.ie/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.it/Lavoro/data-scientist-lavori-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com.mx/Empleo/data-scientist-empleos-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.nl/Vacature/data-scientist-vacatures-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.co.nz/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.at/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://de.glassdoor.ch/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.sg/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://fr.glassdoor.ch/Emploi/data-scientist-emplois-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.co.uk/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/south-africa-data-scientist-jobs-SRCH_IL.0,12_IN211_KO13,27.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/uruguay-data-scientist-jobs-SRCH_IL.0,7_IN246_KO8,22.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/mexico-data-scientist-jobs-SRCH_IL.0,6_IN169_KO7,21.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/costa-rica-data-scientist-jobs-SRCH_IL.0,10_IN57_KO11,25.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/chile-data-scientist-jobs-SRCH_IL.0,5_IN49_KO6,20.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/ecuador-data-scientist-jobs-SRCH_IL.0,7_IN68_KO8,22.htm',\n",
    "        'https://www.glassdoor.com/Job/nigeria-data-scientist-jobs-SRCH_IL.0,7_IN177_KO8,22.htm',\n",
    "        'https://www.glassdoor.com/Job/egypt-data-scientist-jobs-SRCH_IL.0,5_IN69_KO6,20.htm',\n",
    "        'https://www.glassdoor.com/Job/japan-data-scientist-jobs-SRCH_IL.0,5_IN123_KO6,20.htm',\n",
    "        'https://www.glassdoor.com/Job/china-data-scientist-jobs-SRCH_IL.0,5_IN48_KO6,20.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/south-korea-data-scientist-jobs-SRCH_IL.0,11_IN135_KO12,26.htm?jobType=fulltime']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5abfe2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49969c22899f465fa1cd338d95946305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: United States\n",
      "Total number of job listings: 1497, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2686c80a59394ffbbb4d2e8dda2cd418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Argentina\n",
      "Total number of job listings: 58, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830e64b103784276b941a64c72f4a20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Australia\n",
      "Total number of job listings: 204, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01a29469a6e43f2ac96f712b5679388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: België (Dutch)\n",
      "Total number of job listings: 240, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c8eee707b042b6af9a55e2fb110ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Belgique (French)\n",
      "Total number of job listings: 240, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11414b6cffc94e4e922fd57ad81a1304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Brasil\n",
      "Total number of job listings: 107, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d0db2a24a34feca4ef6450d8604194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Canada (English)\n",
      "Total number of job listings: 736, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7338c4ec1841e28627bbad2c13156b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Canada (French)\n",
      "Total number of job listings: 736, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06425aadaab84cdca752c43883406c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Deutschland\n",
      "Total number of job listings: 620, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfd5eb4b5d644f382154e5f4c4ff0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: España\n",
      "Total number of job listings: 472, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f9f0f7918442efaeca6fee3a28254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: France\n",
      "Total number of job listings: 1168, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3de7561fe346988d15c7a5a7a6a2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Hong Kong\n",
      "Total number of job listings: 154, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa04d60516948328dcea27773b52465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: India\n",
      "Total number of job listings: 1619, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51670c04fd91452caa5560e1a45211e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Ireland\n",
      "Total number of job listings: 76, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1cc619c0904fd59ac79d5120b15ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Italia\n",
      "Total number of job listings: 155, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a780bcb5d634cdaa35a18a8b722c17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: México\n",
      "Total number of job listings: 156, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fb688c7d564c749dce1f46271ab06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Nederland\n",
      "Total number of job listings: 513, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5dd83ba9dc47c1a5e604cd24829160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: New Zealand\n",
      "Total number of job listings: 74, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9678b1376820493bb2106953ca9818b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Österreich\n",
      "Total number of job listings: 73, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c90b38b0894e62a9e1ee510a8b5663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Schweiz (German)\n",
      "Total number of job listings: 252, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11eaf7cc27ad455797f31fd5d3462e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Singapore\n",
      "Total number of job listings: 545, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026b64e75b1d40f8bb8f7595a8607ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Suisse (French)\n",
      "Total number of job listings: 425, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975b83a904cb4156a6d3206a2add037d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: United Kingdom\n",
      "Total number of job listings: 1255, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0873b6e851e747b3bedca07baaeb5035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: south-africa\n",
      "Total number of job listings: 111, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2479bebe1442a6aa07f133c65c4e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: uruguay\n",
      "Total number of job listings: 12, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bf169274d34b02ad5efdd6632b53ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: mexico\n",
      "Total number of job listings: 155, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b85515888e242d3b1375be7e228cccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: costa-rica\n",
      "Total number of job listings: 26, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ace31d47204c958d9b75e3ab0a5a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: chile\n",
      "Total number of job listings: 47, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4273dfc6a1b542018e47b331e825d08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: ecuador\n",
      "Total number of job listings: 12, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96533fa013f846f5ac995aa019093f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: nigeria\n",
      "Total number of job listings: 66, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad3d794062744ae8d39526d0efa5fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: egypt\n",
      "Total number of job listings: 31, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e49afe992243efb742570fbb6d0229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: japan\n",
      "Total number of job listings: 99, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226a9e969c4c40a8a314575b71c747c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: china\n",
      "Total number of job listings: 205, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca02ec1056640c5ae7539e87a851c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: south-korea\n",
      "Total number of job listings: 113, number of jobs to be scraped: 5\n",
      "\n",
      "Scraping completed, scraped 5 of 5 jobs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Size</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>...</th>\n",
       "      <th>CEO</th>\n",
       "      <th>Benefits</th>\n",
       "      <th>Opportunities</th>\n",
       "      <th>Comp Benefits</th>\n",
       "      <th>Culture</th>\n",
       "      <th>Management</th>\n",
       "      <th>WorkLife Balance</th>\n",
       "      <th>Pros</th>\n",
       "      <th>Cons</th>\n",
       "      <th>Num Listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CyberCoders\\n4.1</td>\n",
       "      <td>Associate Data Scientist Hybrid</td>\n",
       "      <td>Stamford, CT</td>\n",
       "      <td>United States</td>\n",
       "      <td>Associate Data Scientist Hybrid\\nThis will be ...</td>\n",
       "      <td>Employer Provided Salary:$80K - $100K</td>\n",
       "      <td>$90,000</td>\n",
       "      <td>201 to 500 Employees</td>\n",
       "      <td>Staffing &amp; Subcontracting</td>\n",
       "      <td>Human Resources &amp; Staffing</td>\n",
       "      <td>...</td>\n",
       "      <td>82 %</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"good communication, good people kinda\" (in 1...</td>\n",
       "      <td>[\"bad managment, few offices kinda\" (in 1 revi...</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clarkston Consulting\\n4.4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>Do you want the opportunity to leverage your s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201 to 500 Employees</td>\n",
       "      <td>Business Consulting</td>\n",
       "      <td>Management &amp; Consulting</td>\n",
       "      <td>...</td>\n",
       "      <td>96 %</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"smart people at the top of the field\" (in 7 ...</td>\n",
       "      <td>[\"Training is bad, you will have to figure out...</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mutual of Omaha - Corporate\\n4.2</td>\n",
       "      <td>Data Scientist / Associate Data Scientist - Sr...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>Location: Various Locations\\nWork Type: Full T...</td>\n",
       "      <td>Employer Provided Salary:$71K - $153K</td>\n",
       "      <td>$112,133</td>\n",
       "      <td>5001 to 10000 Employees</td>\n",
       "      <td>Insurance Carriers</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>...</td>\n",
       "      <td>87 %</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"Good place to work depending on your supervi...</td>\n",
       "      <td>[\"Supervisors are unethical and lie.\" (in 4 re...</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CalypsoAI\\n4.3</td>\n",
       "      <td>Data Scientist - Professional Services</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>Data Scientist - Professional Services (Client...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 to 50 Employees</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"Amazing people\" (in 5 reviews), \"Lots of aut...</td>\n",
       "      <td>[\"Beyond building great technologies, we have ...</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oportun Inc\\n4.2</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>United States</td>\n",
       "      <td>Department Overview:\\nABOUT TECHNOLOGY @ OPORT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>Banking &amp; Lending</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>...</td>\n",
       "      <td>92 %</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"focused so you will be able to have chances ...</td>\n",
       "      <td>[\"life balance is a real challenge.\" (in 2 rev...</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>어플라이드 머티리얼즈 코리아</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>south-korea</td>\n",
       "      <td>Are you inspired by how data analytics can be ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>무신사</td>\n",
       "      <td>[MUSINSA] Data Scientist (데이터프로덕트팀)</td>\n",
       "      <td></td>\n",
       "      <td>south-korea</td>\n",
       "      <td>[MUSINSA] Data Scientist (데이터프로덕트팀)\\n무신사는 2001...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>KB데이타시스템</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>south-korea</td>\n",
       "      <td>인터넷·IT·통신·모바일·게임&gt;빅데이터·AI(인공지능)&gt;빅데이터|인터넷·IT·통신·...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>에스케이텔레콤</td>\n",
       "      <td>에이닷 Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>south-korea</td>\n",
       "      <td>이런 일을 합니다.주요 수행업무 및 역할- 대용량 데이터 분석 기반 추천 ML/DL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>south-korea</td>\n",
       "      <td>Are you inspired by how data analytics can be ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Company Name  \\\n",
       "0                    CyberCoders\\n4.1   \n",
       "1           Clarkston Consulting\\n4.4   \n",
       "2    Mutual of Omaha - Corporate\\n4.2   \n",
       "3                      CalypsoAI\\n4.3   \n",
       "4                    Oportun Inc\\n4.2   \n",
       "..                                ...   \n",
       "165                   어플라이드 머티리얼즈 코리아   \n",
       "166                               무신사   \n",
       "167                          KB데이타시스템   \n",
       "168                           에스케이텔레콤   \n",
       "169                 Applied Materials   \n",
       "\n",
       "                                             Job Title      Location  \\\n",
       "0                      Associate Data Scientist Hybrid  Stamford, CT   \n",
       "1                                       Data Scientist        Remote   \n",
       "2    Data Scientist / Associate Data Scientist - Sr...        Remote   \n",
       "3               Data Scientist - Professional Services        Remote   \n",
       "4                                   Sr. Data Scientist        Remote   \n",
       "..                                                 ...           ...   \n",
       "165                                     Data Scientist                 \n",
       "166                [MUSINSA] Data Scientist (데이터프로덕트팀)                 \n",
       "167                                     Data Scientist                 \n",
       "168                                 에이닷 Data Scientist                 \n",
       "169                                     Data Scientist                 \n",
       "\n",
       "           Country                                    Job Description  \\\n",
       "0    United States  Associate Data Scientist Hybrid\\nThis will be ...   \n",
       "1    United States  Do you want the opportunity to leverage your s...   \n",
       "2    United States  Location: Various Locations\\nWork Type: Full T...   \n",
       "3    United States  Data Scientist - Professional Services (Client...   \n",
       "4    United States  Department Overview:\\nABOUT TECHNOLOGY @ OPORT...   \n",
       "..             ...                                                ...   \n",
       "165    south-korea  Are you inspired by how data analytics can be ...   \n",
       "166    south-korea  [MUSINSA] Data Scientist (데이터프로덕트팀)\\n무신사는 2001...   \n",
       "167    south-korea  인터넷·IT·통신·모바일·게임>빅데이터·AI(인공지능)>빅데이터|인터넷·IT·통신·...   \n",
       "168    south-korea  이런 일을 합니다.주요 수행업무 및 역할- 대용량 데이터 분석 기반 추천 ML/DL...   \n",
       "169    south-korea  Are you inspired by how data analytics can be ...   \n",
       "\n",
       "                           Salary Estimate Avg Salary  \\\n",
       "0    Employer Provided Salary:$80K - $100K    $90,000   \n",
       "1                                      NaN        NaN   \n",
       "2    Employer Provided Salary:$71K - $153K   $112,133   \n",
       "3                                      NaN        NaN   \n",
       "4                                      NaN        NaN   \n",
       "..                                     ...        ...   \n",
       "165                                    NaN        NaN   \n",
       "166                                    NaN        NaN   \n",
       "167                                    NaN        NaN   \n",
       "168                                    NaN        NaN   \n",
       "169                                    NaN        NaN   \n",
       "\n",
       "                        Size                                 Industry  \\\n",
       "0       201 to 500 Employees                Staffing & Subcontracting   \n",
       "1       201 to 500 Employees                      Business Consulting   \n",
       "2    5001 to 10000 Employees                       Insurance Carriers   \n",
       "3          1 to 50 Employees  Enterprise Software & Network Solutions   \n",
       "4     1001 to 5000 Employees                        Banking & Lending   \n",
       "..                       ...                                      ...   \n",
       "165                      NaN                                      NaN   \n",
       "166                      NaN                                      NaN   \n",
       "167                      NaN                                      NaN   \n",
       "168                      NaN                                      NaN   \n",
       "169                      NaN                                      NaN   \n",
       "\n",
       "                         Sector  ...   CEO  Benefits Opportunities  \\\n",
       "0    Human Resources & Staffing  ...  82 %       4.3           4.1   \n",
       "1       Management & Consulting  ...  96 %       3.9           4.3   \n",
       "2                     Insurance  ...  87 %       3.4           3.6   \n",
       "3        Information Technology  ...   N/A       NaN           4.4   \n",
       "4            Financial Services  ...  92 %       3.6           4.0   \n",
       "..                          ...  ...   ...       ...           ...   \n",
       "165                         NaN  ...   NaN       NaN           NaN   \n",
       "166                         NaN  ...   NaN       NaN           NaN   \n",
       "167                         NaN  ...   NaN       NaN           NaN   \n",
       "168                         NaN  ...   NaN       NaN           NaN   \n",
       "169                         NaN  ...   NaN       NaN           NaN   \n",
       "\n",
       "    Comp Benefits  Culture  Management  WorkLife Balance  \\\n",
       "0             3.9      4.0         3.9               4.0   \n",
       "1             4.0      4.6         4.4               4.0   \n",
       "2             3.8      4.0         3.6               4.0   \n",
       "3             3.7      4.2         4.4               4.0   \n",
       "4             4.2      4.4         4.0               4.0   \n",
       "..            ...      ...         ...               ...   \n",
       "165           NaN      NaN         NaN               NaN   \n",
       "166           NaN      NaN         NaN               NaN   \n",
       "167           NaN      NaN         NaN               NaN   \n",
       "168           NaN      NaN         NaN               NaN   \n",
       "169           NaN      NaN         NaN               NaN   \n",
       "\n",
       "                                                  Pros  \\\n",
       "0    [\"good communication, good people kinda\" (in 1...   \n",
       "1    [\"smart people at the top of the field\" (in 7 ...   \n",
       "2    [\"Good place to work depending on your supervi...   \n",
       "3    [\"Amazing people\" (in 5 reviews), \"Lots of aut...   \n",
       "4    [\"focused so you will be able to have chances ...   \n",
       "..                                                 ...   \n",
       "165                                                NaN   \n",
       "166                                                NaN   \n",
       "167                                                NaN   \n",
       "168                                                NaN   \n",
       "169                                                NaN   \n",
       "\n",
       "                                                  Cons  Num Listings  \n",
       "0    [\"bad managment, few offices kinda\" (in 1 revi...          1497  \n",
       "1    [\"Training is bad, you will have to figure out...          1497  \n",
       "2    [\"Supervisors are unethical and lie.\" (in 4 re...          1497  \n",
       "3    [\"Beyond building great technologies, we have ...          1497  \n",
       "4    [\"life balance is a real challenge.\" (in 2 rev...          1497  \n",
       "..                                                 ...           ...  \n",
       "165                                                NaN           113  \n",
       "166                                                NaN           113  \n",
       "167                                                NaN           113  \n",
       "168                                                NaN           113  \n",
       "169                                                NaN           113  \n",
       "\n",
       "[170 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_var = \"chrome_driver\"\n",
    "dfs = [get_jobs(url=url, env_var=env_var, num_jobs=5) for url in urls]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f761b4",
   "metadata": {},
   "source": [
    "### Glassdoor Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e19536",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ff6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a12cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2259827",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination = soup.findAll(\"div\", {\"class\": \"paginationFooter\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination = pagination.text.strip()\n",
    "pagination = pagination.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30119d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_num = int(pagination[1])\n",
    "total_pages = int(pagination[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c143a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(page_num, total_pages+1):\n",
    "    if page_num > 1:\n",
    "       url = f\"https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14_IP{page_num}.htm?seniorityType=entrylevel&includeNoSalaryJobs=true\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapes all divs in main section of webpage\n",
    "\n",
    "divs = soup.find_all(\"div\", class_='module p-0 job-search-key-kxun6g exy0tjh2')\n",
    "#divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89388ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes job listings\n",
    "listings = divs[0].find_all('li', class_='react-job-listing')\n",
    "#len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraps all divs wihin each list item, must use find_all instead of find since find returns only first div it finds\n",
    "\n",
    "divs = [item.find_all('div') for item in listings] # finds all divs within each list item, m\n",
    "#divs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff383f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_col = [item[0] for item in divs] # can't use 'find' since item is a list\n",
    "right_col = [item[1] for item in divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70427948",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [item.find_all('a') for item in right_col]\n",
    "#anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b375fbff",
   "metadata": {},
   "source": [
    "##### Company Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186603a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [company[0] for company in anchors]\n",
    "companies = [name.find('span').text.strip() for name in companies]\n",
    "companies[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d9bee",
   "metadata": {},
   "source": [
    "##### Job Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [company[1] for company in anchors]\n",
    "titles = [title.find('span').text.strip() for title in titles]\n",
    "titles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4deadc",
   "metadata": {},
   "source": [
    "##### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [item.find('div', class_='d-flex flex-wrap job-search-key-1m2z0go e1rrn5ka2') for item in right_col]\n",
    "locations = [location.find('span').text.strip() for location in locations]\n",
    "locations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febad0a",
   "metadata": {},
   "source": [
    "##### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in right_col:\n",
    "    \n",
    "    try:\n",
    "        salary = item.find('div', class_='css-1buaf54 pr-xxsm') \n",
    "        salary = salary.find('span', class_='job-search-key-1hbqxax e1wijj240').text.strip()\n",
    "        salary = salary.split()\n",
    "        \n",
    "        if len(salary) <= 4:\n",
    "            salary = salary[0]  \n",
    "\n",
    "        else:\n",
    "            start_sal = salary[0]\n",
    "            max_sal = salary[2]\n",
    "            salary = start_sal + '-' + max_sal\n",
    "    except:\n",
    "        salary = np.nan\n",
    "    \n",
    "    salaries.append(salary)\n",
    "    \n",
    "salaries[0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27d4fb",
   "metadata": {},
   "source": [
    "##### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc382120",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in left_col:\n",
    "    try:\n",
    "        rating = float(item.find('span', class_='job-search-key-srfzj0 e1cjmv6j0').text.strip())\n",
    "    except:\n",
    "        rating = np.nan\n",
    "        \n",
    "    ratings.append(rating)\n",
    "    \n",
    "ratings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad5027",
   "metadata": {},
   "source": [
    "##### Job Listing Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbe404",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [link[0].get(\"href\") for link in anchors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f\"https://www.glassdoor.com{link}\" for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00517b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4191072",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobLink = urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(jobLink, headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.glassdoor.com/job-listing/junior-sas-data-scientist-424-vezita-tech-JV_KO0,29_KE30,41.htm?jl=1008008033583&pos=101&ao=1110586&s=58&guid=0000018202dbf8f9920f2a5cca6a9cc3&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_abea6e2e&cb=1657905347193&jobListingId=1008008033583&cpc=654405A9B1E0A9F5&jrtk=3-0-1g81dnu9rk255801-1g81dnuahghre800-e5f5f92b99790728--6NYlbfkN0A9aFbeqbFpDTCoiHOd6k0wi_YQM7kD-1BJ08Zr1fUkZoDqNJGBVgd-vao9K1qY82N8I1kgImMFzYDAIglGvPLDd_djxuszz8IamPMPcX9as8QrYlFAfWUSEoUwZprhpr8YrJgAbGOJSa943B9zmKGu-lnmily_Vm49BOb2PIn7RfL5JdE5RJMYl4a4fOddmkGLqkobe84SNyejQcQhQjcFNbQpZNv5rzmr7e1JgAowQwQYBG4bbzRgYV0P_JCDy1Jazne5I0HOOD7GQL-5-aHhJieNzuA0BZwASplqp85J7rniTYqXL-CtXVMCZy3veuqlqALVVBNrIGx5nKfq75zgi41wNv1eqaC4acP-dwslixVtnnXUlBvYPrTBRohB4ZabC6Tqnn2hOk7Wtb5VmQPRi3DxrfPO5k-Z-BXsi6UuZs1di84rg1GI0di4MWn60GffS6wFi4pq4DnQu6OFWyYFMpDXWX0eH9AwqOfUDVtCmG8GWOJxwPSuF4JOugPon6v-76TtmoJc406kk32jKkKI&ctt=1657911504446'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59022e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(link, headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67df827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing data\n",
    "\n",
    "print('num companies:', len(companies), 'num titles:', len(titles), \n",
    "      'num locations:', len(locations), 'num salaries:', len(salaries),\n",
    "      'num ratings:', len(ratings), 'num URLS:', len(urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81dab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
