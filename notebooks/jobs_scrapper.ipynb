{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd7d525",
   "metadata": {},
   "source": [
    "# Job Listing Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c0c39",
   "metadata": {},
   "source": [
    "Dataset created from scraping job engine sites including Glassdoor, Indeed, LinkedIn, and Angel using Python's Selenium library and scrapes for the following fields: \n",
    "\n",
    "1. **Company Name**: Name of the company\n",
    "2. **Job Title**: The title of job, eg. Data scientist, junior data scientist, senior data scientist etc.\n",
    "3. **Job Description**: Tells us what is expected out of the job title.\n",
    "4. **Job Requirement**: Required skills\n",
    "5. **Salary Estimate**: Range of salary and the source.\n",
    "6. **Benefits**: Benefits offered by the company including medical insurance, equity, etc.\n",
    "7. **Location**: Location of the job\n",
    "8. **Size**: Range of number of employee working in the company\n",
    "9. **Rating**: It gives the rating of the company\n",
    "10. **Review**: Employee Reviews\n",
    "11. **Industry**: Industry of the company\n",
    "12. **Sector**: Sector in which company works\n",
    "13. **Revenue**: Total revenue of the company per year\n",
    "14. **Num Listings**: Total number of job listings for a country "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbd660",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chromedriver - https://sites.google.com/chromium.org/driver/\n",
    "#pip install -U selenium\n",
    "#conda install -c conda-forge python-dotenv\n",
    "#conda install -c conda-forge webdriver-manager\n",
    "#conda install tqdm\n",
    "#pip install oschmod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d1ec1",
   "metadata": {},
   "source": [
    "### Add Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0078cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import oschmod\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm # works for both terminal and notebook\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, WebDriverException, ElementClickInterceptedException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7fe57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0b7a0",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbd383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_setup(url, chrome_var=None, chrome_path=None, linux_unix=True):\n",
    "    \n",
    "    options = Options()\n",
    "    #options.add_argument(\"--window-size=1120,1000\")\n",
    "    #\"--kiosk\")\n",
    "    if chrome_path is None and chrome_var is None:\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url)\n",
    "        return driver\n",
    "    \n",
    "    # if storing path to chrome_driver in a .env file\n",
    "    if chrome_var:\n",
    "        load_dotenv(find_dotenv()) \n",
    "        CHROME_DRIVER = os.environ[chrome_var]\n",
    "    elif chrome_path:\n",
    "        CHROME_DRIVER = chrome_path\n",
    "    \n",
    "    oschmod.set_mode(CHROME_DRIVER, 0o755) # set read/execute permissions\n",
    "    service = Service(CHROME_DRIVER)\n",
    " \n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_in(email, password):\n",
    "    \n",
    "    if find_dotenv():\n",
    "        load_dotenv(find_dotenv()) \n",
    "        email = os.environ[email]\n",
    "        password = os.environ[password]\n",
    "    \n",
    "    try:\n",
    "        signInLink = driver.find_element(By.XPATH, \"//a[@class='link ml-xxsm']\").click()  #clicking Sign In link.\n",
    "\n",
    "        # Enter email\n",
    "        emailField = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//label[@class='css-w3qhip eb2o9h0']\"))).click()\n",
    "        emailField = driver.find_element(By.XPATH, \"//input[@class='css-1kmcde e1h5k8h92']\")\n",
    "        emailField.send_keys(email, Keys.RETURN)\n",
    "\n",
    "            # Enter password\n",
    "        passwordField = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//label[@class='css-w3qhip eb2o9h0']\"))).click()\n",
    "        passwordField = driver.find_element(By.XPATH, \"//input[@class='css-1kmcde e1h5k8h92']\")\n",
    "        passwordField.send_keys(password, Keys.RETURN)\n",
    "        \n",
    "        driver.find_element(By.XPATH, \"//button[@name='submit']\").click()\n",
    "\n",
    "    except WebDriverException:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(df, filename='datascience_US'):\n",
    "    \n",
    "    directory_path = '../data/'\n",
    "    filepath = directory_path + filename + '.csv'\n",
    "    exists = os.path.exists(directory_path)\n",
    "    \n",
    "    if not exists:\n",
    "        os.makedirs(directory_path)\n",
    "        \n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f72c40",
   "metadata": {},
   "source": [
    "### Glassdoor Job Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60459d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(url, chrome_var=None, chrome_path=None, num_jobs=30, verbose=False, slp_time=5):\n",
    "\n",
    "    if chrome_var:\n",
    "        driver = driver_setup(url, chrome_var)\n",
    "    elif chrome_path:\n",
    "        driver = driver_setup(url, chrome_path)\n",
    "    else:\n",
    "        driver = driver_setup(url)\n",
    "    \n",
    "    jobs = []\n",
    "    jobs_count = len(jobs)\n",
    "    pbar = tqdm(total=num_jobs) # Init progress bar\n",
    "    \n",
    "    time.sleep(slp_time)\n",
    "    \n",
    "    result = re.search(r\"SRCH_IL\", url) # Check URL for countries that were typed into search bar\n",
    "    \n",
    "    if result:\n",
    "        country = re.search(r'Job\\/(.*?)-data-scientist', url).group(1)\n",
    "    else:\n",
    "        try:\n",
    "            country = driver.find_element(By.XPATH, '//div[@class=\"css-m3gjah egu3u860\"]/div[@class=\"selectedLabel\"]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            country = np.nan\n",
    "    \n",
    "    print(\"Country:\", country)\n",
    "    \n",
    "    try:\n",
    "        total_listings = driver.find_element(By.XPATH, \"//p[@data-test='jobsCount']\").text.split()\n",
    "            \n",
    "        if len(total_listings) == 0:\n",
    "            total_listings = int(driver.find_element(By.XPATH, \"//h1[@data-test='jobCount-H1title']\").text.split()[0])\n",
    "        else:\n",
    "            total_listings = int(total_listings[0])\n",
    "            \n",
    "    except NoSuchElementException:\n",
    "            total_listings = np.nan \n",
    "            \n",
    "    \n",
    "    if num_jobs > total_listings:\n",
    "        \n",
    "        print(\"The number of jobs to be scrapped: {} exceeds the number of listings: {}\".format(num_jobs, total_listings))\n",
    "        \n",
    "        num_jobs = total_listings\n",
    "        \n",
    "        print(\"The number of jobs has been updated to reflect the number of listings\")\n",
    "        print(\"\")\n",
    "    \n",
    "    \n",
    "    print(\"Total number of job listings: {}, number of jobs to be scraped: {}\".format(total_listings, num_jobs))\n",
    "    print(\"\")\n",
    "\n",
    "    while jobs_count < num_jobs:\n",
    "        \n",
    "        time.sleep(slp_time)\n",
    "        time.sleep(.1)\n",
    "        \n",
    "        job_listings = driver.find_elements(By.CLASS_NAME, \"react-job-listing\")\n",
    "        \n",
    "        for listing in job_listings:\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "            if jobs_count >= num_jobs:\n",
    "                print(\"Scraping completed, scraped {} of {} jobs\".format(jobs_count, num_jobs))\n",
    "                break\n",
    "            \n",
    "            listing.click()\n",
    "            time.sleep(2)   \n",
    "\n",
    "            \n",
    "            try:\n",
    "                driver.find_element(By.XPATH, \"//div[@class='qual_x_close']\").click()  #In case survey pops up. \n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            try: \n",
    "                driver.find_element(By.XPATH, \"//span[@alt='Close']\").click()  #clicking to the X.   \n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            \n",
    "            collected_successfully = False\n",
    "            \n",
    "            while not collected_successfully:\n",
    "                try:\n",
    "                    job_title = driver.find_element(By.XPATH,'//div[@class=\"css-1j389vi e1tk4kwz2\"]').text.strip()\n",
    "                    location = driver.find_element(By.XPATH,'//div[@class=\"css-56kyx5 e1tk4kwz1\"]').text.strip()\n",
    "                    job_description = driver.find_element(By.XPATH,'//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "                    collected_successfully = True        \n",
    "                except:\n",
    "                    \n",
    "\n",
    "            try: # sometimes there are listings that are posted without a company name\n",
    "                company_name = driver.find_element(By.XPATH,'//div[@class=\"css-xuk5ye e1tk4kwz5\"]').text.strip() #returns any element which is direct parent.\n",
    "            except:\n",
    "                company_name = np.nan\n",
    "            \n",
    "            try:\n",
    "                salary_range = driver.find_element(By.XPATH, '//span[@class=\"css-1hbqxax e1wijj240\"]').text.strip()\n",
    "            except NoSuchElementException:\n",
    "                salary_range = np.nan\n",
    "\n",
    "            try:\n",
    "                salary_avg = driver.find_element(By.XPATH, '//div[@class=\"css-y2jiyn e2u4hf18\"]').text.strip()\n",
    "                salary_avg = salary_avg.split()[0]\n",
    "            except NoSuchElementException:\n",
    "                salary_avg = np.nan\n",
    "\n",
    "            \n",
    "            # Search for Company Container\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.ID, 'CompanyContainer')\n",
    "                \n",
    "                try:\n",
    "                    size = driver.find_element(By.XPATH, \n",
    "                                               '(//div[@class=\"d-flex justify-content-start css-daag8o e1pvx6aw2\"])[1]//span[2]').text.strip()\n",
    "    \n",
    "                except NoSuchElementException:\n",
    "                    size = np.nan\n",
    "\n",
    "                try:\n",
    "                    industry = driver.find_element(By.XPATH, \n",
    "                                               '(//div[@class=\"d-flex justify-content-start css-daag8o e1pvx6aw2\"])[4]//span[2]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    industry = np.nan\n",
    "\n",
    "                try:\n",
    "                    sector = driver.find_element(By.XPATH, \n",
    "                                               '(//div[@class=\"d-flex justify-content-start css-daag8o e1pvx6aw2\"])[5]//span[2]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    sector = np.nan\n",
    "\n",
    "                try:\n",
    "                    revenue = driver.find_element(By.XPATH, \n",
    "                                               '(//div[@class=\"d-flex justify-content-start css-daag8o e1pvx6aw2\"])[6]//span[2]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    revenue = np.nan\n",
    "\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                size = np.nan\n",
    "                industry = np.nan\n",
    "                sector = np.nan\n",
    "                revenue = np.nan\n",
    "\n",
    "            \n",
    "            # Search for Reviews Container\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, '//div[@data-test=\"company-ratings\"]')\n",
    "\n",
    "                try:\n",
    "                    rating = float(driver.find_element(By.XPATH, '//div[@class=\"mr-sm css-ey2fjr e1pr2f4f3\"]').text.strip())\n",
    "                except NoSuchElementException:\n",
    "                    rating = np.nan\n",
    "\n",
    "                try:\n",
    "                    recommend = driver.find_element(By.XPATH, '(//div[@class=\"d-flex top css-rkhv2t e1o78bat1\"])[1]//div[1]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    recommend = np.nan\n",
    "\n",
    "                try:\n",
    "                    ceo = driver.find_element(By.XPATH, '//div[@class=\"css-vkhqai ceoApprove\"]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    ceo = np.nan\n",
    "\n",
    "                try:\n",
    "                    opportunities = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[3]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    opportunities = np.nan\n",
    "                try:\n",
    "                    comp_benefits = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[6]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    comp_benefits = np.nan\n",
    "\n",
    "                try:\n",
    "                    culture = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[9]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    culture = np.nan\n",
    "\n",
    "                try:\n",
    "                    management = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[12]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    management = np.nan\n",
    "\n",
    "                try:\n",
    "                    workLife = float(driver.find_element(By.XPATH, '//ul[@class=\"css-1t3mcrv erz4gkm2\"]/span[15]').text.strip())        \n",
    "                except NoSuchElementException:\n",
    "                    workLife = np.nan\n",
    "\n",
    "\n",
    "            except NoSuchElementException:\n",
    "                rating = np.nan\n",
    "                recommend = np.nan\n",
    "                ceo = np.nan\n",
    "                opportunities = np.nan\n",
    "                comp_benefits = np.nan\n",
    "                culture = np.nan\n",
    "                management = np.nan\n",
    "                workLife = np.nan\n",
    "\n",
    "\n",
    "            # Get Employee Reviews\n",
    "            try: \n",
    "                driver.find_element(By.ID, 'ReviewsContainer')\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    pro_reviews = driver.find_element(By.XPATH, \n",
    "                                                      '(//div[@class=\"css-1sfecah e1vn3ovn1\"])[1]//div') # check for pros\n",
    "\n",
    "                    pro_reviews = pro_reviews.find_elements(By.XPATH, \"following-sibling::p\")\n",
    "                    pros = [review.text for review in pro_reviews]  \n",
    "\n",
    "                except NoSuchElementException: \n",
    "                    pros = np.nan\n",
    "\n",
    "                try:\n",
    "                    con_reviews = driver.find_element(By.XPATH, \n",
    "                                                      '(//div[@class=\"css-1sfecah e1vn3ovn1\"])[2]//div')\n",
    "\n",
    "                    con_reviews = con_reviews.find_elements(By.XPATH, \"following-sibling::p\")\n",
    "                    cons = [review.text for review in con_reviews]    \n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    cons = np.nan\n",
    "                \n",
    "                try:\n",
    "                    reviewsURL = driver.find_element(By.XPATH, '//a[@class=\"seeAll pb-0 pt-std css-922fyb euq8tqg0\"]').get_attribute('href')\n",
    "                except NoSuchElementException:\n",
    "                    reviewsURL = np.nan\n",
    "\n",
    "            except NoSuchElementException: \n",
    "                pros = np.nan\n",
    "                cons = np.nan\n",
    "                reviewsURL = np.nan\n",
    "\n",
    "            # Get Benefits Rating and Reviews\n",
    "            try: \n",
    "                driver.find_element(By.CLASS_NAME, 'p-std')\n",
    "\n",
    "                try: \n",
    "                    benefits_rating = float(driver.find_element(By.XPATH, '//div[@class=\"ratingNum mr-sm\"]').text.strip())\n",
    "\n",
    "                except NoSuchElementException: \n",
    "                    benefits_rating = np.nan\n",
    "                \n",
    "                try:\n",
    "                    benefitsURL = driver.find_element(By.XPATH, '//a[@class=\"css-b6lfw4 mt-0 p-std d-flex justify-content-center\"]').get_attribute('href')\n",
    "                except NoSuchElementException:\n",
    "                    benefitsURL = np.nan\n",
    "\n",
    "            except NoSuchElementException: \n",
    "                benefits_rating = np.nan\n",
    "                \n",
    "\n",
    "            jobs.append({\"Company Name\": company_name,\n",
    "                        \"Job Title\": job_title, \n",
    "                        \"Location\": location,\n",
    "                        \"Country\": country,\n",
    "                        \"Job Description\": job_description, \n",
    "                        \"Salary Estimate\": salary_range,\n",
    "                        \"Avg Salary\": salary_avg,\n",
    "                        \"Size\": size,\n",
    "                        \"Industry\": industry,\n",
    "                        \"Sector\": sector,\n",
    "                        \"Revenue\": revenue,\n",
    "                        \"Rating\": rating,\n",
    "                        \"Recommend\": recommend,\n",
    "                        \"CEO\": ceo,\n",
    "                        \"Benefits\": benefits_rating,\n",
    "                        \"Opportunities\": opportunities,\n",
    "                        \"Comp Benefits\": comp_benefits,\n",
    "                        \"Culture\": culture,\n",
    "                        \"Management\": management,\n",
    "                        \"WorkLife Balance\": workLife,\n",
    "                        \"Pros\": pros,\n",
    "                        \"Cons\": cons,\n",
    "                        \"Num Listings\": total_listings,\n",
    "                        \"Reviews URL\": reviewsURL,\n",
    "                        \"Benefits URL\": benefitsURL})\n",
    "            \n",
    "        \n",
    "            jobs_count = len(jobs)\n",
    "            \n",
    "            if not verbose:\n",
    "                print(\"Scraped {} out of {} job listings\".format(jobs_count, num_jobs), end='\\r')\n",
    "            \n",
    "            # print for debugging purposes\n",
    "            if verbose:\n",
    "                print(\"Company Name: {}\".format(company_name))\n",
    "                print(\"Job Title: {}\".format(job_title))\n",
    "                print(\"Location: {}\".format(location))\n",
    "                print(\"Country: {}\".format(country))\n",
    "                print(\"Job Description: {}\".format(job_description[:500]))\n",
    "                print(\"Salary Estimate: {}\".format(salary_range))\n",
    "                print(\"Avg Salary: {}\".format(salary_avg))\n",
    "                print(\"Size: {}\".format(size))\n",
    "                print(\"Industry: {}\".format(industry))\n",
    "                print(\"Sector: {}\".format(sector))\n",
    "                print(\"Revenue: {}\".format(revenue))\n",
    "                print(\"Rating: {}\".format(rating))\n",
    "                print(\"Recommend To Friend: {}\".format(recommend))\n",
    "                print(\"Approve of CEO: {}\".format(ceo))\n",
    "                print(\"Benefits Rating: {}\".format(benefits_rating))\n",
    "                print(\"Career Opportunities: {}\".format(opportunities))\n",
    "                print(\"Comp & Benefits: {}\".format(comp_benefits))\n",
    "                print(\"Culture & Values: {}\".format(culture))\n",
    "                print(\"Senior Managment: {}\".format(management))\n",
    "                print(\"Work Life Balance: {}\".format(workLife))\n",
    "                print(\"Pros: \", pros)\n",
    "                print(\"Cons: \", cons)\n",
    "                print(\"\")\n",
    "                print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "                print(\"\")\n",
    "\n",
    "        # clicking on the \"next page button\"\n",
    "\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, '//button[@data-test=\"pagination-next\"]').click()\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping completed, scraped {}, out of {} job listings.\".format(jobs_count, num_jobs))\n",
    "            break\n",
    " \n",
    "    \n",
    "    pbar.close()\n",
    "    driver.close()\n",
    "    return pd.DataFrame(jobs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var = \"CHROME_DRIVER\"\n",
    "url = 'https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime&remoteWorkType=1&sortBy=date_desc'\n",
    "\n",
    "df = get_jobs(url=url, chrome_var=env_var)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6948b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://www.glassdoor.com/Reviews/Univision-Reviews-E6046.htm'\n",
    "#url = 'https://www.glassdoor.ca/Reviews/Indeed-Reviews-E100561.htm'\n",
    "#url = 'https://www.glassdoor.com/Reviews/Salesforce-Reviews-E11159.htm'\n",
    "url = 'https://www.glassdoor.com.ar/Evaluaciones/Chase-Evaluaciones-E690765.htm'\n",
    "email = \"GLASSDOOR_EMAIL\"\n",
    "password = \"GLASSDOOR_PASSWORD\"\n",
    "\n",
    "def get_reviews(url, email, password, verbose=False):\n",
    "    \n",
    "    reviews = []\n",
    "\n",
    "    driver = driver_setup(url, chrome_var=\"CHROME_DRIVER\")\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, \"//div[@class='gdUserLogin authInlineContainer gdGrid bg-white']\")\n",
    "        sign_in(email, password)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, \"//div[@class='qual_x_close']\").click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, \"//div[@class='qual_x_close']\").click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Make the demographics dropdown clickable to select different options\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']\")\n",
    "\n",
    "        dropdown = driver.find_element(By.XPATH, \"//div[@class='mb-xsm e1hgsnla1 css-wcay7z ew8s0qn0']/select\")\n",
    "        driver.execute_script(\"arguments[0].style.display = 'block';\", dropdown)\n",
    "        time.sleep(2)\n",
    "\n",
    "        drpdn_optns = dropdown.find_elements(By.XPATH, \"option\")\n",
    "        drpdn_optns = [option.get_attribute('value') for option in drpdn_optns] \n",
    "\n",
    "\n",
    "        dropdown = Select(dropdown)\n",
    "\n",
    "        for option in drpdn_optns: # iterates through menu option and selects them\n",
    "            time.sleep(.1)\n",
    "            dropdown.select_by_value(option)  # get ratings based on demographics\n",
    "            time.sleep(2)\n",
    "\n",
    "\n",
    "            if option == 'raceEthnicity':\n",
    "                \n",
    "                try:\n",
    "                    asian = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[1]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    asian = np.nan\n",
    "                try:\n",
    "                    black = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[2]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    black = np.nan\n",
    "                try:\n",
    "                    hispanic = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[3]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    hispanic = np.nan\n",
    "                try:\n",
    "                    indigenous = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[4]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    indigenous = np.nan\n",
    "                try:\n",
    "                    middleEastern = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[5]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    middleEastern = np.nan\n",
    "                try:\n",
    "                    white = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[6]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    white = np.nan\n",
    "                try:\n",
    "                    other = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[7]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    other = np.nan    \n",
    "                \n",
    "\n",
    "            elif option == 'gender':\n",
    "                \n",
    "                try:\n",
    "                    men = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[1]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    men = np.nan    \n",
    "                try:\n",
    "                    women = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[2]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    women = np.nan    \n",
    "                try:\n",
    "                    trans = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[3]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    trans = np.nan    \n",
    "              \n",
    "\n",
    "            elif option == 'sexualOrientation':\n",
    "                \n",
    "                try:\n",
    "                    heterosexual = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[1]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    heterosexual = np.nan \n",
    "                try:\n",
    "                    lgbtq = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[2]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    lgbtq = np.nan \n",
    "               \n",
    "\n",
    "            elif option == 'disability':\n",
    "                \n",
    "                try:\n",
    "                    nonDisabled = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[1]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    nonDisabled = np.nan \n",
    "                \n",
    "                try:\n",
    "                    disabled = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[2]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    disabled = np.nan \n",
    "                               \n",
    "\n",
    "            elif option == 'parentOrCaregiver':\n",
    "                \n",
    "                try:\n",
    "                    caregiver = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[1]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    caregiver = np.nan \n",
    "                \n",
    "                try:\n",
    "                    nonCaregiver = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[2]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    nonCaregiver = np.nan \n",
    "                \n",
    "                try:\n",
    "                    parents = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[3]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    parents = np.nan \n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                try:\n",
    "                    nonVeterans = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[1]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    nonVeterans = np.nan \n",
    "                \n",
    "                try:\n",
    "                    veterans = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[2]\").text.split()[-2]\n",
    "                except NoSuchElementException:\n",
    "                    veterans = np.nan \n",
    "                    \n",
    "\n",
    "    except NoSuchElementException:\n",
    "        asian = np.nan\n",
    "        black = np.nan\n",
    "        hispanic = np.nan\n",
    "        indigenous = np.nan\n",
    "        middleEastern = np.nan\n",
    "        white = np.nan\n",
    "        other = np.nan\n",
    "        men = np.nan\n",
    "        women = np.nan\n",
    "        trans = np.nan\n",
    "        heterosexual = np.nan\n",
    "        lgbtq = np.nan\n",
    "        nonDisabled = np.nan\n",
    "        disabled = np.nan\n",
    "        caregiver = np.nan\n",
    "        nonCaregiver = np.nan\n",
    "        nonVeterans = np.nan\n",
    "        veterans = np.nan\n",
    "    \n",
    "    reviews.append({\"Asian\":asian,\n",
    "                 \"Black\":black,\n",
    "                 \"Hispanic/Latinx\":hispanic,\n",
    "                 \"Indigenous\":indigenous,\n",
    "                 \"Middle Eastern\":middleEastern,\n",
    "                 \"White\":white,\n",
    "                 \"Men\":men,\n",
    "                 \"Women\":women,\n",
    "                 \"Transexual/Non-Binary\":trans,\n",
    "                 \"Heterosexual\":heterosexual,\n",
    "                 \"lgbtq\":lgbtq,\n",
    "                 \"Non-Disabled\", nonDisabled,\n",
    "                 \"Disabled\": disabled,\n",
    "                 \"Caregiver\": caregiver,\n",
    "                 \"Non-Veteran\": nonVeterans,\n",
    "                 \"Veterans\": veterans        \n",
    "                })\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Asian:\", asian)\n",
    "        print(\"Black:\", black)\n",
    "        print(\"Hispanic:\", hispanic)\n",
    "        print(\"Indigenous:\", indigenous)\n",
    "        print(\"MiddleEastern:\", middleEastern)\n",
    "        print(\"White:\", white)\n",
    "        print(\"Men:\", men)\n",
    "        print(\"Women:\", women)\n",
    "        print(\"Transexual/Non-Binary:\", trans)\n",
    "        print(\"Heterosexual:\", heterosexual)\n",
    "        print(\"lgbtq:\", lgbtq)\n",
    "        print(\"Non-Disabled:\", nonDisabled)\n",
    "        print(\"Disabled:\", disabled)\n",
    "        print(\"Caregiver:\", caregiver)\n",
    "        print(\"Non-Veteran:\", nonVeterans)\n",
    "        print(\"Veterans:\", veterans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58eaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime&remoteWorkType=1&sortBy=date_desc',\n",
    "        'https://www.glassdoor.com.ar/Empleo/data-scientist-empleos-SRCH_KO0,14.htm?jobType=fulltime', \n",
    "        'https://www.glassdoor.com.au/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://nl.glassdoor.be/Vacature/data-scientist-vacatures-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://fr.glassdoor.be/Emploi/data-scientist-emplois-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com.br/Vaga/data-scientist-vagas-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.ca/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://fr.glassdoor.ca/Emploi/data-scientist-emplois-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.de/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.es/Empleo/data-scientist-empleos-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.fr/Emploi/data-scientist-emplois-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com.hk/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.co.in/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.ie/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.it/Lavoro/data-scientist-lavori-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com.mx/Empleo/data-scientist-empleos-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.nl/Vacature/data-scientist-vacatures-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.co.nz/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.at/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://de.glassdoor.ch/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.sg/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://fr.glassdoor.ch/Emploi/data-scientist-emplois-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.co.uk/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/south-africa-data-scientist-jobs-SRCH_IL.0,12_IN211_KO13,27.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/uruguay-data-scientist-jobs-SRCH_IL.0,7_IN246_KO8,22.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/mexico-data-scientist-jobs-SRCH_IL.0,6_IN169_KO7,21.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/costa-rica-data-scientist-jobs-SRCH_IL.0,10_IN57_KO11,25.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/chile-data-scientist-jobs-SRCH_IL.0,5_IN49_KO6,20.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/ecuador-data-scientist-jobs-SRCH_IL.0,7_IN68_KO8,22.htm',\n",
    "        'https://www.glassdoor.com/Job/nigeria-data-scientist-jobs-SRCH_IL.0,7_IN177_KO8,22.htm',\n",
    "        'https://www.glassdoor.com/Job/egypt-data-scientist-jobs-SRCH_IL.0,5_IN69_KO6,20.htm',\n",
    "        'https://www.glassdoor.com/Job/japan-data-scientist-jobs-SRCH_IL.0,5_IN123_KO6,20.htm',\n",
    "        'https://www.glassdoor.com/Job/china-data-scientist-jobs-SRCH_IL.0,5_IN48_KO6,20.htm?jobType=fulltime',\n",
    "        'https://www.glassdoor.com/Job/south-korea-data-scientist-jobs-SRCH_IL.0,11_IN135_KO12,26.htm?jobType=fulltime']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14.htm?jobType=fulltime&remoteWorkType=1&sortBy=date_desc'\n",
    "driver = driver_setup(url, chrome_var=\"chrome_driver\")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "job_listings = driver.find_elements(By.CLASS_NAME, \"react-job-listing\")\n",
    "\n",
    "for listing in job_listings:\n",
    "    \n",
    "    listing.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        emailButton = driver.find_element(By.XPATH, \"//button[@class='jaCreateAccountEmailSignUpButton']\").click()  \n",
    "    \n",
    "        # Enter email\n",
    "        emailField = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//label[@class='css-w3qhip eb2o9h0']\"))).click()\n",
    "        email = driver.find_element(By.XPATH, \"//input[@class='css-1kmcde e1h5k8h92']\")\n",
    "        email.send_keys(GLASSDOOR_EMAIL, Keys.RETURN)\n",
    "\n",
    "        # Enter password\n",
    "        passwordField = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//label[@class='css-w3qhip eb2o9h0']\"))).click()\n",
    "        password = driver.find_element(By.XPATH, \"//input[@class='css-1kmcde e1h5k8h92']\")\n",
    "        password.send_keys(GLASSDOOR_PASSWORD, Keys.RETURN)\n",
    "    \n",
    "    except WebDriverException:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "signIn_button = driver.find_element(By.XPATH, '//button[text()=\"Sign In\"]')\n",
    "driver.implicitly_wait(5)\n",
    "signIn_button.click()\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581968f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# find ratings based on demographics\n",
    "try:\n",
    "    demographics = driver.find_elements(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button\")\n",
    "\n",
    "    for element in demographics:\n",
    "\n",
    "        ethnicity = element.text.split()[0]\n",
    "        rating = element.text.split()[-2]\n",
    "\n",
    "        if rating == '—':\n",
    "            rating = np.nan\n",
    "        else:\n",
    "            rating = float(rating)\n",
    "\n",
    "        if ethnicity == 'Asian':\n",
    "            asian = rating\n",
    "        elif ethnicity == 'Black':\n",
    "            black = rating\n",
    "        elif ethnicity == 'Hispanic':\n",
    "            hispanic = rating\n",
    "        elif ethnicity == 'Indigenous':\n",
    "            indigenous = rating\n",
    "        elif ethnicity == 'Middle':\n",
    "            middleEastern = rating\n",
    "        elif ethnicity == 'White':\n",
    "            white = rating\n",
    "        else:\n",
    "            other = rating\n",
    "            \n",
    "except NoSuchElementException:\n",
    "    asian = np.nan\n",
    "    black = np.nan\n",
    "    hispanic = np.nan\n",
    "    indigenous = np.nan\n",
    "    middleEastern = np.nan\n",
    "    white = np.nan\n",
    "    other = np.nan\n",
    "\n",
    "print(\"Asian:\", asian)\n",
    "print(\"Black:\", black)\n",
    "print(\"Hispanic:\", hispanic)\n",
    "print(\"Indigenous:\", indigenous)\n",
    "print(\"MiddleEastern:\", middleEastern)\n",
    "print(\"White:\", white)\n",
    "print(\"Other:\", other)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "try:\n",
    "    driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[1]\").text.split()\n",
    "\n",
    "except NoSuchElementException:\n",
    "    asian = np.nan\n",
    "\n",
    "try:\n",
    "    black = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[2]\").text.split()\n",
    "except NoSuchElementException:\n",
    "    black = np.nan\n",
    "\n",
    "try:\n",
    "    hispanic = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[3]\").text.split()\n",
    "except NoSuchElementException:\n",
    "    hispanic = np.nan\n",
    "\n",
    "try:\n",
    "    indigenous = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[4]\").text.split()\n",
    "except NoSuchElementException:\n",
    "    indigenous = np.nan\n",
    "\n",
    "try:\n",
    "    middleEastern = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[5]\").text.split()\n",
    "except NoSuchElementException:\n",
    "    middleEastern = np.nan\n",
    "\n",
    "try:\n",
    "    white = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[6]\").text.split()\n",
    "except NoSuchElementException:\n",
    "    white = np.nan\n",
    "\n",
    "try:\n",
    "    islander = driver.find_element(By.XPATH, \"//div[@class='d-flex flex-wrap demographicOptions']/button[7]\").text.split()\n",
    "except NoSuchElementException:\n",
    "    islander = np.nan\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfe2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var = \"chrome_driver\"\n",
    "dfs = [get_jobs(url=url, chrome_var=env_var, num_jobs=5) for url in urls]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f761b4",
   "metadata": {},
   "source": [
    "### Glassdoor Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e19536",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ff6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a12cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2259827",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination = soup.findAll(\"div\", {\"class\": \"paginationFooter\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination = pagination.text.strip()\n",
    "pagination = pagination.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30119d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_num = int(pagination[1])\n",
    "total_pages = int(pagination[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c143a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(page_num, total_pages+1):\n",
    "    if page_num > 1:\n",
    "       url = f\"https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14_IP{page_num}.htm?seniorityType=entrylevel&includeNoSalaryJobs=true\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapes all divs in main section of webpage\n",
    "\n",
    "divs = soup.find_all(\"div\", class_='module p-0 job-search-key-kxun6g exy0tjh2')\n",
    "#divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89388ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes job listings\n",
    "listings = divs[0].find_all('li', class_='react-job-listing')\n",
    "#len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraps all divs wihin each list item, must use find_all instead of find since find returns only first div it finds\n",
    "\n",
    "divs = [item.find_all('div') for item in listings] # finds all divs within each list item, m\n",
    "#divs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff383f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_col = [item[0] for item in divs] # can't use 'find' since item is a list\n",
    "right_col = [item[1] for item in divs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70427948",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [item.find_all('a') for item in right_col]\n",
    "#anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b375fbff",
   "metadata": {},
   "source": [
    "##### Company Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186603a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [company[0] for company in anchors]\n",
    "companies = [name.find('span').text.strip() for name in companies]\n",
    "companies[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d9bee",
   "metadata": {},
   "source": [
    "##### Job Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [company[1] for company in anchors]\n",
    "titles = [title.find('span').text.strip() for title in titles]\n",
    "titles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4deadc",
   "metadata": {},
   "source": [
    "##### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [item.find('div', class_='d-flex flex-wrap job-search-key-1m2z0go e1rrn5ka2') for item in right_col]\n",
    "locations = [location.find('span').text.strip() for location in locations]\n",
    "locations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febad0a",
   "metadata": {},
   "source": [
    "##### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fb96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in right_col:\n",
    "    \n",
    "    try:\n",
    "        salary = item.find('div', class_='css-1buaf54 pr-xxsm') \n",
    "        salary = salary.find('span', class_='job-search-key-1hbqxax e1wijj240').text.strip()\n",
    "        salary = salary.split()\n",
    "        \n",
    "        if len(salary) <= 4:\n",
    "            salary = salary[0]  \n",
    "\n",
    "        else:\n",
    "            start_sal = salary[0]\n",
    "            max_sal = salary[2]\n",
    "            salary = start_sal + '-' + max_sal\n",
    "    except:\n",
    "        salary = np.nan\n",
    "    \n",
    "    salaries.append(salary)\n",
    "    \n",
    "salaries[0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27d4fb",
   "metadata": {},
   "source": [
    "##### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc382120",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in left_col:\n",
    "    try:\n",
    "        rating = float(item.find('span', class_='job-search-key-srfzj0 e1cjmv6j0').text.strip())\n",
    "    except:\n",
    "        rating = np.nan\n",
    "        \n",
    "    ratings.append(rating)\n",
    "    \n",
    "ratings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ad5027",
   "metadata": {},
   "source": [
    "##### Job Listing Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbe404",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [link[0].get(\"href\") for link in anchors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f\"https://www.glassdoor.com{link}\" for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00517b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4191072",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobLink = urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(jobLink, headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.glassdoor.com/job-listing/junior-sas-data-scientist-424-vezita-tech-JV_KO0,29_KE30,41.htm?jl=1008008033583&pos=101&ao=1110586&s=58&guid=0000018202dbf8f9920f2a5cca6a9cc3&src=GD_JOB_AD&t=SR&vt=w&ea=1&cs=1_abea6e2e&cb=1657905347193&jobListingId=1008008033583&cpc=654405A9B1E0A9F5&jrtk=3-0-1g81dnu9rk255801-1g81dnuahghre800-e5f5f92b99790728--6NYlbfkN0A9aFbeqbFpDTCoiHOd6k0wi_YQM7kD-1BJ08Zr1fUkZoDqNJGBVgd-vao9K1qY82N8I1kgImMFzYDAIglGvPLDd_djxuszz8IamPMPcX9as8QrYlFAfWUSEoUwZprhpr8YrJgAbGOJSa943B9zmKGu-lnmily_Vm49BOb2PIn7RfL5JdE5RJMYl4a4fOddmkGLqkobe84SNyejQcQhQjcFNbQpZNv5rzmr7e1JgAowQwQYBG4bbzRgYV0P_JCDy1Jazne5I0HOOD7GQL-5-aHhJieNzuA0BZwASplqp85J7rniTYqXL-CtXVMCZy3veuqlqALVVBNrIGx5nKfq75zgi41wNv1eqaC4acP-dwslixVtnnXUlBvYPrTBRohB4ZabC6Tqnn2hOk7Wtb5VmQPRi3DxrfPO5k-Z-BXsi6UuZs1di84rg1GI0di4MWn60GffS6wFi4pq4DnQu6OFWyYFMpDXWX0eH9AwqOfUDVtCmG8GWOJxwPSuF4JOugPon6v-76TtmoJc406kk32jKkKI&ctt=1657911504446'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59022e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(link, headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67df827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing data\n",
    "\n",
    "print('num companies:', len(companies), 'num titles:', len(titles), \n",
    "      'num locations:', len(locations), 'num salaries:', len(salaries),\n",
    "      'num ratings:', len(ratings), 'num URLS:', len(urls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81dab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
